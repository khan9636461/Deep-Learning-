{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozS6QNlujlzq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHyWimurn9Ka"
      },
      "outputs": [],
      "source": [
        "# Define the Inception v1 (GoogLeNet) model\n",
        "def inception_v1(input_shape=(32, 32, 3)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # 1x1 Convolution\n",
        "    conv1x1 = Conv2D(64, (1, 1), padding='same', activation='relu')(inputs)\n",
        "\n",
        "    # 1x1 Convolution + 3x3 Convolution\n",
        "    conv3x3_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(inputs)\n",
        "    conv3x3_2 = Conv2D(128, (3, 3), padding='same', activation='relu')(conv3x3_1)\n",
        "\n",
        "    # 1x1 Convolution + 5x5 Convolution\n",
        "    conv5x5_1 = Conv2D(32, (1, 1), padding='same', activation='relu')(inputs)\n",
        "    conv5x5_2 = Conv2D(128, (5, 5), padding='same', activation='relu')(conv5x5_1)\n",
        "\n",
        "    # 3x3 MaxPooling + 1x1 Convolution\n",
        "    maxpool_1 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
        "    maxpool_2 = Conv2D(32, (1, 1), padding='same', activation='relu')(maxpool_1)\n",
        "\n",
        "    # Concatenate all branches\n",
        "    inception_output = concatenate([conv1x1, conv3x3_2, conv5x5_2, maxpool_2], axis=-1)\n",
        "\n",
        "    # Add Fully Connected Layers\n",
        "    x = AveragePooling2D(pool_size=(8, 8))(inception_output)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW1Odg5HoFwF",
        "outputId": "eb95f499-b4e7-48d7-fa10-d7cac5e3e19d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1422s\u001b[0m 2s/step - accuracy: 0.3615 - loss: 1.7526 - val_accuracy: 0.5344 - val_loss: 1.2950\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1399s\u001b[0m 2s/step - accuracy: 0.5462 - loss: 1.2611 - val_accuracy: 0.5859 - val_loss: 1.1587\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1426s\u001b[0m 2s/step - accuracy: 0.6061 - loss: 1.1061 - val_accuracy: 0.6054 - val_loss: 1.1015\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1445s\u001b[0m 2s/step - accuracy: 0.6392 - loss: 1.0113 - val_accuracy: 0.6346 - val_loss: 1.0260\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1441s\u001b[0m 2s/step - accuracy: 0.6739 - loss: 0.9207 - val_accuracy: 0.6481 - val_loss: 1.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Instantiate the model\n",
        "model_v1 = inception_v1()\n",
        "\n",
        "# Compile the model\n",
        "model_v1.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_v1.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Save the model\n",
        "model_v1.save('inception_v1_cifar10.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUxYtkCJoIki"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, BatchNormalization, ReLU, concatenate\n",
        "\n",
        "# Define the Inception v2 model with optimizations\n",
        "def inception_v2(input_shape=(32, 32, 3)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # 1x1 Convolution\n",
        "    conv1x1 = Conv2D(64, (1, 1), padding='same')(inputs)\n",
        "    conv1x1 = BatchNormalization()(conv1x1)\n",
        "    conv1x1 = ReLU()(conv1x1)\n",
        "\n",
        "    # 1x1 Convolution + 3x3 Convolution (Factorized)\n",
        "    conv3x3_1 = Conv2D(64, (1, 1), padding='same')(inputs)\n",
        "    conv3x3_1 = BatchNormalization()(conv3x3_1)\n",
        "    conv3x3_1 = ReLU()(conv3x3_1)\n",
        "    conv3x3_2 = Conv2D(128, (3, 3), padding='same')(conv3x3_1)\n",
        "    conv3x3_2 = BatchNormalization()(conv3x3_2)\n",
        "    conv3x3_2 = ReLU()(conv3x3_2)\n",
        "\n",
        "    # 1x1 Convolution + 5x5 Convolution (Factorized)\n",
        "    conv5x5_1 = Conv2D(32, (1, 1), padding='same')(inputs)\n",
        "    conv5x5_1 = BatchNormalization()(conv5x5_1)\n",
        "    conv5x5_1 = ReLU()(conv5x5_1)\n",
        "    conv5x5_2 = Conv2D(128, (5, 5), padding='same')(conv5x5_1)\n",
        "    conv5x5_2 = BatchNormalization()(conv5x5_2)\n",
        "    conv5x5_2 = ReLU()(conv5x5_2)\n",
        "\n",
        "    # 3x3 MaxPooling + 1x1 Convolution\n",
        "    maxpool_1 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
        "    maxpool_2 = Conv2D(32, (1, 1), padding='same')(maxpool_1)\n",
        "    maxpool_2 = BatchNormalization()(maxpool_2)\n",
        "    maxpool_2 = ReLU()(maxpool_2)\n",
        "\n",
        "    # Concatenate all branches\n",
        "    inception_output = concatenate([conv1x1, conv3x3_2, conv5x5_2, maxpool_2], axis=-1)\n",
        "\n",
        "    # Add Fully Connected Layers\n",
        "    x = AveragePooling2D(pool_size=(8, 8))(inception_output)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DJgxr5ZqOGK"
      },
      "outputs": [],
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Instantiate the model\n",
        "model_v2 = inception_v2()\n",
        "\n",
        "# Compile the model\n",
        "model_v2.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_v2.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Save the model\n",
        "model_v2.save('inception_v2_cifar10.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}